{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Review Analysis by implementing Naive Bayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGTfYzfduyqb",
        "colab_type": "code",
        "outputId": "9fbd4391-37fb-4f8b-a4d0-9825cc33c530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize,RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GucQ2Wl-vXQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train = [\"The movie was awesome and great ! I loved it with all my heart\",\n",
        "          \"The movie was very boring and i hate it.\",\n",
        "          \"Worst movie ever!\",\n",
        "          \"Blockbuster of the year ! stupendious movie\",\n",
        "          \"Great movie overall\",\n",
        "          \"Bad bad Movie\",\n",
        "          \"Best Movie!\",\n",
        "          \"An unpleasant movie\",\n",
        "           \"not bad movie\",\n",
        "           \"spectacular movie.worth watch\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr_oOid0u4Dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = [1,0,0,1,1,0,1,0,1,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM8Yd0SOu5Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('your_file.txt', 'w') as f:\n",
        "    for item in x_train:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGKHDoyMu68A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"your_file.txt\",\"r\") as f:\n",
        "    temp = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPMYUQknvNsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "stopwords = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AcKuUVHvBWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataPreprocess_nlp(text):\n",
        "  text = text.lower()\n",
        "  tokenized_text = tokenizer.tokenize(text)\n",
        "  swRemoved_tokenized = [elem for elem in tokenized_text if elem not in stopwords]\n",
        "  stemmed = [ps.stem(word) for word in swRemoved_tokenized]\n",
        "  processed_text = \" \".join(stemmed)\n",
        "  return processed_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZGzAHPlvtrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rld1Nuzcw7EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prior(label):\n",
        "  Dr = float()\n",
        "  Nr = float()\n",
        "  Dr = len(y_train)\n",
        "  Nr = list(y_train).count(label)\n",
        "  return Nr/Dr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo5uPfd9x_AK",
        "colab_type": "text"
      },
      "source": [
        "Conditional probablities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdNAf2NWx-Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_word_in_a_class(word,label,x=x_train):\n",
        "    count = float()\n",
        "    word = word.lower()\n",
        "    temp = x[y_train==label]\n",
        "    for i in temp:\n",
        "        for j in i.split(' '):\n",
        "            if j == word:\n",
        "                count += 1\n",
        "    return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl1MXJsXxa3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def total_words_in_a_class(label,x=x_train):\n",
        "  count = float()\n",
        "  labels = x[y_train==label]\n",
        "  for i in labels:\n",
        "    count = count + len(i.split(' '))\n",
        "  return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkGq4jV9zYgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vocabulary_size():\n",
        "  label = [0,1]\n",
        "  class_0 = []\n",
        "  for i in label:\n",
        "    terms=x_train[y_train==i]\n",
        "    for j in terms:\n",
        "      j = j.lower()\n",
        "      for k in j.split(' '):\n",
        "        if k not in class_0:\n",
        "          class_0.append(k)\n",
        "  return len(class_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvyFFSyf6DZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conditional_probabilities(word,label):\n",
        "  Nr = count_word_in_a_class(word,label)+1\n",
        "  Dr = total_words_in_a_class(label)+vocabulary_size()\n",
        "  return Nr/Dr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Xm4knmFxB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def final_prediction(text,x_train=x_train,y_train = y_train):\n",
        "    final_list = []\n",
        "    labels = [0,1]\n",
        "    processedText = dataPreprocess_nlp(text)\n",
        "    for i in labels:\n",
        "        P = prior(i)\n",
        "        likelihood_val = 1.0\n",
        "        for word in processedText.split(' '):\n",
        "            likelihood_val *= conditional_probabilities(word,i)\n",
        "        P *= likelihood_val\n",
        "        final_list.append(P)\n",
        "    predection = np.argmax(final_list)\n",
        "    print(predection)\n",
        "    print(final_list)\n",
        "    return predection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWdx5M2AHIaL",
        "colab_type": "code",
        "outputId": "b73aed04-4f01-45c8-f7e6-ee1a52eb6693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "revieww = input()\n",
        "k = final_prediction(revieww)\n",
        "if (k == 0):\n",
        "  print(\"NEGATIVE Review\")\n",
        "else:\n",
        "  print(\"POSITIVE Review\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "boring movie it was\n",
            "0\n",
            "[0.00014792899408284027, 0.00013774104683195594]\n",
            "NEGATIVE Review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH1GbLACvfU9",
        "colab_type": "code",
        "outputId": "0b5fb3fd-0740-435a-b659-090b09d4185b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "revieww = input()\n",
        "k = final_prediction(revieww)\n",
        "if (k == 0):\n",
        "  print(\"NEGATIVE Review\")\n",
        "else:\n",
        "  print(\"POSITIVE Review\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "great movie\n",
            "1\n",
            "[0.00014792899408284027, 0.0002754820936639119]\n",
            "POSITIVE Review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqSm2En0vgC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}